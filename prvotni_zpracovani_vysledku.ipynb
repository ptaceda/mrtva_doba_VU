{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ptaceda/mrtva_doba_VU/blob/main/zpracovani_vysledku.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HL9QwIrA_kJA",
        "outputId": "712ba12e-8197-4a50-deda-f22b6ffda4a2"
      },
      "outputs": [],
      "source": [
        "import pydicom # type: ignore\n",
        "import matplotlib.pyplot as plt # type: ignore\n",
        "import pandas as pd # type: ignore\n",
        "import os\n",
        "from glob import glob\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Head1_EM', 'Head2_EM', 'Head1_SC1', 'Head2_SC1', 'Head1_SC2', 'Head2_SC2']\n",
            "['Head1_EM', 'Head2_EM', 'Head1_SC1', 'Head2_SC1', 'Head1_SC2', 'Head2_SC2']\n",
            "['Head1_EM', 'Head2_EM', 'Head1_SC1', 'Head2_SC1', 'Head1_SC2', 'Head2_SC2']\n",
            "['Head1_EM', 'Head2_EM', 'Head1_SC1', 'Head2_SC1', 'Head1_SC2', 'Head2_SC2']\n",
            "['Head1_EM', 'Head2_EM', 'Head1_SC1', 'Head2_SC1', 'Head1_SC2', 'Head2_SC2']\n",
            "['Head1_EM', 'Head2_EM', 'Head1_SC1', 'Head2_SC1', 'Head1_SC2', 'Head2_SC2']\n",
            "['Head1_EM', 'Head2_EM', 'Head1_SC1', 'Head2_SC1', 'Head1_SC2', 'Head2_SC2']\n",
            "['Head1_EM', 'Head2_EM', 'Head1_SC1', 'Head2_SC1', 'Head1_SC2', 'Head2_SC2']\n",
            "['Head1_EM', 'Head2_EM', 'Head1_SC1', 'Head2_SC1', 'Head1_SC2', 'Head2_SC2']\n",
            "['Head1_EM', 'Head2_EM', 'Head1_SC1', 'Head2_SC1', 'Head1_SC2', 'Head2_SC2']\n",
            "['Head1_EM', 'Head2_EM', 'Head1_SC1', 'Head2_SC1', 'Head1_SC2', 'Head2_SC2']\n",
            "['Head1_EM', 'Head2_EM', 'Head1_SC1', 'Head2_SC1', 'Head1_SC2', 'Head2_SC2']\n",
            "['Head1_EM', 'Head2_EM', 'Head1_SC1', 'Head2_SC1', 'Head1_SC2', 'Head2_SC2']\n",
            "['Head1_EM', 'Head2_EM', 'Head1_SC1', 'Head2_SC1', 'Head1_SC2', 'Head2_SC2']\n",
            "['Head1_EM', 'Head2_EM', 'Head1_SC1', 'Head2_SC1', 'Head1_SC2', 'Head2_SC2']\n",
            "['Head1_EM', 'Head2_EM', 'Head1_SC1', 'Head2_SC1', 'Head1_SC2', 'Head2_SC2']\n",
            "['Head1_EM', 'Head2_EM', 'Head1_SC1', 'Head2_SC1', 'Head1_SC2', 'Head2_SC2']\n",
            "['Head1_EM', 'Head2_EM', 'Head1_SC1', 'Head2_SC1', 'Head1_SC2', 'Head2_SC2']\n",
            "['Head1_EM', 'Head2_EM', 'Head1_SC1', 'Head2_SC1', 'Head1_SC2', 'Head2_SC2']\n",
            "['Head1_EM', 'Head2_EM', 'Head1_SC1', 'Head2_SC1', 'Head1_SC2', 'Head2_SC2']\n"
          ]
        }
      ],
      "source": [
        "## OPTIMA prvotni DATA\n",
        "optima_folder = 'Optima'\n",
        "\n",
        "optima_mds = glob(os.path.join(optima_folder, 'MD*'))\n",
        "\n",
        "for md in optima_mds:\n",
        "    text_file_path = os.path.join(md, 'vysledky.txt')\n",
        "    with open(text_file_path, 'w+') as file:\n",
        "        file.write('Typ_Datum_Kamera    Hlava_okno   Count_rate\\n')\n",
        "\n",
        "    dead_time_path = glob(os.path.join(md, 'MD_*.dcm'))[0]\n",
        "    pozadi_path = glob(os.path.join(md, 'Pozadi_*.dcm'))[0]\n",
        "    data_paths = [dead_time_path, pozadi_path]\n",
        "    \n",
        "    dt_data = pydicom.dcmread(dead_time_path)\n",
        "    pozadi_data = pydicom.dcmread(pozadi_path)\n",
        "    datas = [dt_data, pozadi_data]\n",
        "\n",
        "    for dicom_data, path in zip(datas, data_paths):\n",
        "        # Get the base filename without extension\n",
        "        base_filename = os.path.basename(path)\n",
        "        filename_without_extension = os.path.splitext(base_filename)[0]\n",
        "\n",
        "        # Access the custom group containing Dataset Names and print them\n",
        "        if (0x0011, 0x1012) in dicom_data:\n",
        "            dataset_names = dicom_data[0x0011, 0x1012].value\n",
        "            dataset_acq_time = dicom_data[0x0018, 0x1242].value*0.001\n",
        "\n",
        "            # Extract the pixel array from the DICOM data\n",
        "            if 'PixelData' in dicom_data:\n",
        "                pixel_array = dicom_data.pixel_array\n",
        "\n",
        "                # Check if the pixel array has the expected number of slices\n",
        "                num_slices = pixel_array.shape[0]\n",
        "                if num_slices != len(dataset_names):\n",
        "                    print(\"Warning: Number of slices does not match the number of dataset names.\")\n",
        "\n",
        "                # Create a figure and a 2x3 grid of subplots\n",
        "                fig, axes = plt.subplots(2, 3, figsize=(15, 10), dpi = 200)\n",
        "                \n",
        "                # Flatten the axes array for easy iteration\n",
        "                axes = axes.flatten()\n",
        "\n",
        "                # Separate the indices of \"Head1\" and \"Head2\" datasets\n",
        "                head1_indices = [i for i, name in enumerate(dataset_names) if \"Head1\" in name]\n",
        "                head2_indices = [i for i, name in enumerate(dataset_names) if \"Head2\" in name]\n",
        "\n",
        "                head1_dict = {}\n",
        "                head2_dict = {}\n",
        "\n",
        "                # Loop through each \"Head1\" slice and plot it in the first row\n",
        "                for idx, head1_idx in enumerate(head1_indices):\n",
        "                    ax = axes[idx]\n",
        "                    ax.imshow(pixel_array[head1_idx], cmap='gray')\n",
        "                    ax.set_title(dataset_names[head1_idx])\n",
        "                    ax.axis('off')  # Hide the axes ticks\n",
        "\n",
        "                    # Calculate and print the sum of pixel values\n",
        "                    pixel_sum = pixel_array[head1_idx].sum()\n",
        "                    count_rate = pixel_sum / dataset_acq_time\n",
        "                    with open(text_file_path, 'a+') as file:\n",
        "                        file.write(f\"{filename_without_extension}   {dataset_names[head1_idx]}   {round(count_rate,2)}\\n\")\n",
        "\n",
        "                # Loop through each \"Head2\" slice and plot it in the second row\n",
        "                for idx, head2_idx in enumerate(head2_indices):\n",
        "                    ax = axes[idx + 3]\n",
        "                    ax.imshow(pixel_array[head2_idx], cmap='gray')\n",
        "                    ax.set_title(dataset_names[head2_idx])\n",
        "                    ax.axis('off')  # Hide the axes ticks\n",
        "\n",
        "                    # Calculate and print the sum of pixel values\n",
        "                    pixel_sum = pixel_array[head2_idx].sum()\n",
        "                    count_rate = pixel_sum / dataset_acq_time\n",
        "                    with open(text_file_path, 'a+') as file:\n",
        "                        file.write(f\"{filename_without_extension}   {dataset_names[head2_idx]}  {round(count_rate,2)}\\n\")\n",
        "\n",
        "                # Adjust layout to avoid overlap\n",
        "                fig.savefig(os.path.join(md, f'{filename_without_extension}.jpg'), bbox_inches='tight')\n",
        "                plt.close()\n",
        "            else:\n",
        "                print(\"No image data found in the DICOM file.\")\n",
        "        else:\n",
        "            print(\"The DICOM file does not contain the expected custom group with dataset names.\")\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "## DISCOVERY prvotni DATA\n",
        "discovery_folder = 'Discovery'\n",
        "a = 3\n",
        "\n",
        "discovery_mds = glob(os.path.join(discovery_folder, 'MD*'))\n",
        "\n",
        "for md in discovery_mds:\n",
        "    text_file_path = os.path.join(md, 'vysledky.txt')\n",
        "    with open(text_file_path, 'w+') as file:\n",
        "        file.write('Vysledky mereni mrtve doby:\\n')\n",
        "        file.write('Typ_Datum_kamera    Hlava_okno  Pocet_akum_impulsu  Acq_time  Count_rate\\n')\n",
        "\n",
        "    dead_time_path = glob(os.path.join(md, 'MD_*.dcm'))[0]\n",
        "    pozadi_path = glob(os.path.join(md, 'Pozadi_*.dcm'))[0]\n",
        "    data_paths = [dead_time_path, pozadi_path]\n",
        "    \n",
        "    dt_data = pydicom.dcmread(dead_time_path)\n",
        "    pozadi_data = pydicom.dcmread(pozadi_path)\n",
        "    datas = [dt_data, pozadi_data]\n",
        "\n",
        "    for dicom_data, path in zip(datas, data_paths):\n",
        "        # Get the base filename without extension\n",
        "        base_filename = os.path.basename(path)\n",
        "        filename_without_extension = os.path.splitext(base_filename)[0]\n",
        "\n",
        "        # Access the custom group containing Dataset Names and print them\n",
        "        if (0x0011, 0x1012) in dicom_data:\n",
        "            dataset_names = dicom_data[0x0011, 0x1012].value\n",
        "            dataset_acq_time = dicom_data[0x0018, 0x1242].value*0.001\n",
        "\n",
        "            # Extract the pixel array from the DICOM data\n",
        "            if 'PixelData' in dicom_data:\n",
        "                pixel_array = dicom_data.pixel_array\n",
        "\n",
        "                # Check if the pixel array has the expected number of slices\n",
        "                num_slices = pixel_array.shape[0]\n",
        "                if num_slices != len(dataset_names):\n",
        "                    print(\"Warning: Number of slices does not match the number of dataset names.\")\n",
        "\n",
        "                # Create a figure and a 2x3 grid of subplots\n",
        "                fig, axes = plt.subplots(2, 3, figsize=(15, 10), dpi = 200)\n",
        "                \n",
        "                # Flatten the axes array for easy iteration\n",
        "                axes = axes.flatten()\n",
        "\n",
        "                # Separate the indices of \"Head1\" and \"Head2\" datasets\n",
        "                head1_indices = [i for i, name in enumerate(dataset_names) if \"Head1\" in name]\n",
        "                head2_indices = [i for i, name in enumerate(dataset_names) if \"Head2\" in name]\n",
        "\n",
        "                # Loop through each \"Head1\" slice and plot it in the first row\n",
        "                for idx, head1_idx in enumerate(head1_indices):\n",
        "                    ax = axes[idx]\n",
        "                    ax.imshow(pixel_array[head1_idx], cmap='gray')\n",
        "                    ax.set_title(dataset_names[head1_idx])\n",
        "                    ax.axis('off')  # Hide the axes ticks\n",
        "\n",
        "                    # Calculate and print the sum of pixel values\n",
        "                    pixel_sum = pixel_array[head1_idx].sum()\n",
        "                    count_rate = pixel_sum / dataset_acq_time\n",
        "                    with open(text_file_path, 'a+') as file:\n",
        "                        file.write(f\"{filename_without_extension}   {dataset_names[head1_idx]}  {pixel_sum} {dataset_acq_time} {round(count_rate,2)}\\n\")\n",
        "\n",
        "                # Loop through each \"Head2\" slice and plot it in the second row\n",
        "                for idx, head2_idx in enumerate(head2_indices):\n",
        "                    ax = axes[idx + 3]\n",
        "                    ax.imshow(pixel_array[head2_idx], cmap='gray')\n",
        "                    ax.set_title(dataset_names[head2_idx])\n",
        "                    ax.axis('off')  # Hide the axes ticks\n",
        "\n",
        "                    # Calculate and print the sum of pixel values\n",
        "                    pixel_sum = pixel_array[head2_idx].sum()\n",
        "                    count_rate = pixel_sum / dataset_acq_time\n",
        "                    with open(text_file_path, 'a+') as file:\n",
        "                        file.write(f\"{filename_without_extension}   {dataset_names[head2_idx]} {pixel_sum} {dataset_acq_time} {round(count_rate,2)}\\n\")\n",
        "                        file.close()\n",
        "\n",
        "                # Adjust layout to avoid overlap\n",
        "                fig.savefig(os.path.join(md, f'{filename_without_extension}.jpg'), bbox_inches='tight')\n",
        "                plt.close()\n",
        "            else:\n",
        "                print(\"No image data found in the DICOM file.\")\n",
        "        else:\n",
        "            print(\"The DICOM file does not contain the expected custom group with dataset names.\")\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "26751.11111111111 15559.776905017536\n"
          ]
        }
      ],
      "source": [
        "# ZKOUŠKA JESTLI VŠE FUNGUJE A FUNGUJE\n",
        "\n",
        "from dicom_file_separator import separate_dicom_file\n",
        "from tew_correction import tew_correction\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "path = \"Discovery/MD_08072024_povedene/MD_08072024_Discovery.dcm\"\n",
        "images = separate_dicom_file(path)\n",
        "tew_1 = tew_correction(images[\"Head1_EM\"], images[\"Head1_SC1\"], images[\"Head1_SC2\"])\n",
        "\n",
        "bez_korekce = np.sum(images[\"Head1_EM\"])/images[\"Acq_time\"]\n",
        "s_korekci = np.sum(tew_1)/images[\"Acq_time\"]\n",
        "\n",
        "print(bez_korekce, s_korekci)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "26751.11111111111 23.801666666666666\n",
            "15559.776905017536 20.146251051179096\n",
            "26606.736166800318 24.028333333333332\n",
            "16049.818140091667 20.20515628516268\n",
            "26107.838827838827 24.305\n",
            "15556.302832772293 20.462846948323445\n",
            "25585.600439681228 23.946666666666665\n",
            "15200.334877492394 20.184489156569427\n",
            "24720.75325680382 24.268333333333334\n",
            "14668.898230998851 20.460646282675384\n",
            "22495.455043259226 24.121666666666666\n",
            "13367.689817542558 20.25380017529522\n",
            "21865.120632279533 24.30666666666667\n",
            "12986.278269797884 20.43844763055348\n",
            "19896.60172179429 23.89\n",
            "11787.961060607662 19.9601061246728\n",
            "17587.416352588265 24.065\n",
            "10543.843657277677 20.163234137559368\n",
            "15563.192312825304 24.205\n",
            "9299.972468589154 20.52445368297623\n"
          ]
        }
      ],
      "source": [
        "# DISCOVERY DATA mrtve doby\n",
        "\n",
        "from dicom_file_separator import separate_dicom_file\n",
        "from tew_correction import tew_correction\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "discovery_folder = 'Discovery'\n",
        "discovery_mds = glob(os.path.join(discovery_folder, 'MD*'))\n",
        "\n",
        "for md in discovery_mds:\n",
        "    ### nejprve rozhazeni jednotlivych dat\n",
        "    dead_time_path = glob(os.path.join(md, 'MD_*.dcm'))[0]\n",
        "    pozadi_path = glob(os.path.join(md, 'Pozadi_*.dcm'))[0]\n",
        "\n",
        "    dt_data = separate_dicom_file(dead_time_path)\n",
        "    bg_data = separate_dicom_file(pozadi_path)\n",
        "\n",
        "    dt_acq_time = dt_data[\"Acq_time\"]\n",
        "    bg_acq_time = bg_data[\"Acq_time\"]\n",
        "\n",
        "    dt_1_no_corr = dt_data[\"Head1_EM\"]\n",
        "    bg_1_no_corr = bg_data[\"Head1_EM\"]\n",
        "\n",
        "    dt_1_tew_corr = tew_correction(dt_data[\"Head1_EM\"], dt_data[\"Head1_SC1\"], dt_data[\"Head1_SC2\"])\n",
        "    bg_1_tew_corr = tew_correction(bg_data[\"Head1_EM\"], bg_data[\"Head1_SC1\"], bg_data[\"Head1_SC2\"])\n",
        "\n",
        "    dt_2_no_corr = dt_data[\"Head2_EM\"]\n",
        "    bg_2_no_corr = bg_data[\"Head2_EM\"]\n",
        "    \n",
        "    dt_2_tew_corr = tew_correction(dt_data[\"Head2_EM\"], dt_data[\"Head2_SC1\"], dt_data[\"Head2_SC2\"])\n",
        "    bg_2_tew_corr = tew_correction(bg_data[\"Head2_EM\"], bg_data[\"Head2_SC1\"], bg_data[\"Head2_SC2\"])\n",
        "\n",
        "    ### ----\n",
        "    ### vypocty count rates\n",
        "\n",
        "    cr_1_no_corr = np.sum(dt_1_no_corr)/dt_acq_time - np.sum(bg_1_no_corr)/bg_acq_time\n",
        "    cr_2_no_corr = np.sum(dt_2_no_corr)/dt_acq_time - np.sum(bg_2_no_corr)/bg_acq_time\n",
        "\n",
        "    cr_1_tew_corr = np.sum(dt_1_tew_corr)/dt_acq_time - np.sum(bg_1_tew_corr)/bg_acq_time\n",
        "    cr_2_tew_corr = np.sum(dt_2_tew_corr)/dt_acq_time - np.sum(bg_2_tew_corr)/bg_acq_time\n",
        "\n",
        "    print(np.sum(dt_1_no_corr)/dt_acq_time, np.sum(bg_1_no_corr)/bg_acq_time)\n",
        "    print(np.sum(dt_1_tew_corr)/dt_acq_time, np.sum(bg_1_tew_corr)/bg_acq_time)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPS9LmK4fyIorOF99S2Fobj",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
