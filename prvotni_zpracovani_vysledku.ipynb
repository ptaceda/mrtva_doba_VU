{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ptaceda/mrtva_doba_VU/blob/main/zpracovani_vysledku.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "Configuration file not found: config.json",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[13], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m project_dir\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Get the project directory\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m project_dir \u001b[38;5;241m=\u001b[39m \u001b[43mget_project_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Set the working directory to the project directory\u001b[39;00m\n\u001b[0;32m     34\u001b[0m os\u001b[38;5;241m.\u001b[39mchdir(project_dir)\n",
            "Cell \u001b[1;32mIn[13], line 9\u001b[0m, in \u001b[0;36mget_project_directory\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m config_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(config_file_path):\n\u001b[1;32m----> 9\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfiguration file not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_file_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(config_file_path) \u001b[38;5;28;01mas\u001b[39;00m config_file:\n\u001b[0;32m     12\u001b[0m     config \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(config_file)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: Configuration file not found: config.json"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import platform\n",
        "\n",
        "def get_project_directory():\n",
        "    # Load configuration\n",
        "    config_file_path = 'config.json'\n",
        "    if not os.path.exists(config_file_path):\n",
        "        raise FileNotFoundError(f\"Configuration file not found: {config_file_path}\")\n",
        "\n",
        "    with open(config_file_path) as config_file:\n",
        "        config = json.load(config_file)\n",
        "\n",
        "    # Determine the operating system\n",
        "    system_name = platform.system().lower()\n",
        "\n",
        "    # Select path based on the operating system\n",
        "    if system_name == 'windows':\n",
        "        project_dir = config.get('windows')\n",
        "    elif system_name == 'darwin':  # macOS is 'darwin'\n",
        "        project_dir = config.get('mac')\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported operating system: {system_name}\")\n",
        "\n",
        "    if not project_dir:\n",
        "        raise ValueError(f\"Path for operating system '{system_name}' not found in configuration\")\n",
        "\n",
        "    return project_dir\n",
        "\n",
        "# Get the project directory\n",
        "project_dir = get_project_directory()\n",
        "\n",
        "# Set the working directory to the project directory\n",
        "os.chdir(project_dir)\n",
        "print(\"Current working directory:\", os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HL9QwIrA_kJA",
        "outputId": "712ba12e-8197-4a50-deda-f22b6ffda4a2"
      },
      "outputs": [],
      "source": [
        "import pydicom # type: ignore\n",
        "import matplotlib.pyplot as plt # type: ignore\n",
        "import pandas as pd # type: ignore\n",
        "import os\n",
        "from glob import glob\n",
        "import sys\n",
        "\n",
        "from codes.custom_library import Graf_1_2\n",
        "\n",
        "aktivity = {\n",
        "    \"20240708\" : 700.589,\n",
        "    \"20240709\" : 640.979,\n",
        "    \"20240710\" : 586.294,\n",
        "    \"20240711\" : 537.692,\n",
        "    \"20240712\" : 495.958,\n",
        "    \"20240714\" : 404.370,\n",
        "    \"20240715\" : 379.365,\n",
        "    \"20240717\" : 324.319,\n",
        "    \"20240719\" : 266.596,\n",
        "    \"20240721\" : 226.576\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## OPTIMA prvotni DATA\n",
        "optima_folder = 'Optima'\n",
        "\n",
        "optima_mds = glob(os.path.join(optima_folder, 'MD*'))\n",
        "\n",
        "for md in optima_mds:\n",
        "    text_file_path = os.path.join(md, 'vysledky.txt')\n",
        "    with open(text_file_path, 'w+') as file:\n",
        "        file.write('Typ_Datum_Kamera    Hlava_okno   Count_rate\\n')\n",
        "\n",
        "    dead_time_path = glob(os.path.join(md, 'MD_*.dcm'))[0]\n",
        "    pozadi_path = glob(os.path.join(md, 'Pozadi_*.dcm'))[0]\n",
        "    data_paths = [dead_time_path, pozadi_path]\n",
        "    \n",
        "    dt_data = pydicom.dcmread(dead_time_path)\n",
        "    pozadi_data = pydicom.dcmread(pozadi_path)\n",
        "    datas = [dt_data, pozadi_data]\n",
        "\n",
        "    for dicom_data, path in zip(datas, data_paths):\n",
        "        # Get the base filename without extension\n",
        "        base_filename = os.path.basename(path)\n",
        "        filename_without_extension = os.path.splitext(base_filename)[0]\n",
        "\n",
        "        # Access the custom group containing Dataset Names and print them\n",
        "        if (0x0011, 0x1012) in dicom_data:\n",
        "            dataset_names = dicom_data[0x0011, 0x1012].value\n",
        "            dataset_acq_time = dicom_data[0x0018, 0x1242].value*0.001\n",
        "\n",
        "            # Extract the pixel array from the DICOM data\n",
        "            if 'PixelData' in dicom_data:\n",
        "                pixel_array = dicom_data.pixel_array\n",
        "\n",
        "                # Check if the pixel array has the expected number of slices\n",
        "                num_slices = pixel_array.shape[0]\n",
        "                if num_slices != len(dataset_names):\n",
        "                    print(\"Warning: Number of slices does not match the number of dataset names.\")\n",
        "\n",
        "                # Create a figure and a 2x3 grid of subplots\n",
        "                fig, axes = plt.subplots(2, 3, figsize=(15, 10), dpi = 200)\n",
        "                \n",
        "                # Flatten the axes array for easy iteration\n",
        "                axes = axes.flatten()\n",
        "\n",
        "                # Separate the indices of \"Head1\" and \"Head2\" datasets\n",
        "                head1_indices = [i for i, name in enumerate(dataset_names) if \"Head1\" in name]\n",
        "                head2_indices = [i for i, name in enumerate(dataset_names) if \"Head2\" in name]\n",
        "\n",
        "                head1_dict = {}\n",
        "                head2_dict = {}\n",
        "\n",
        "                # Loop through each \"Head1\" slice and plot it in the first row\n",
        "                for idx, head1_idx in enumerate(head1_indices):\n",
        "                    ax = axes[idx]\n",
        "                    ax.imshow(pixel_array[head1_idx], cmap='gray')\n",
        "                    ax.set_title(dataset_names[head1_idx])\n",
        "                    ax.axis('off')  # Hide the axes ticks\n",
        "\n",
        "                    # Calculate and print the sum of pixel values\n",
        "                    pixel_sum = pixel_array[head1_idx].sum()\n",
        "                    count_rate = pixel_sum / dataset_acq_time\n",
        "                    with open(text_file_path, 'a+') as file:\n",
        "                        file.write(f\"{filename_without_extension}   {dataset_names[head1_idx]}   {round(count_rate,2)}\\n\")\n",
        "\n",
        "                # Loop through each \"Head2\" slice and plot it in the second row\n",
        "                for idx, head2_idx in enumerate(head2_indices):\n",
        "                    ax = axes[idx + 3]\n",
        "                    ax.imshow(pixel_array[head2_idx], cmap='gray')\n",
        "                    ax.set_title(dataset_names[head2_idx])\n",
        "                    ax.axis('off')  # Hide the axes ticks\n",
        "\n",
        "                    # Calculate and print the sum of pixel values\n",
        "                    pixel_sum = pixel_array[head2_idx].sum()\n",
        "                    count_rate = pixel_sum / dataset_acq_time\n",
        "                    with open(text_file_path, 'a+') as file:\n",
        "                        file.write(f\"{filename_without_extension}   {dataset_names[head2_idx]}  {round(count_rate,2)}\\n\")\n",
        "\n",
        "                # Adjust layout to avoid overlap\n",
        "                fig.savefig(os.path.join(md, f'{filename_without_extension}.jpg'), bbox_inches='tight')\n",
        "                plt.close()\n",
        "            else:\n",
        "                print(\"No image data found in the DICOM file.\")\n",
        "        else:\n",
        "            print(\"The DICOM file does not contain the expected custom group with dataset names.\")\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## DISCOVERY prvotni DATA\n",
        "discovery_folder = 'Discovery'\n",
        "a = 3\n",
        "\n",
        "discovery_mds = glob(os.path.join(discovery_folder, 'MD*'))\n",
        "\n",
        "for md in discovery_mds:\n",
        "    text_file_path = os.path.join(md, 'vysledky.txt')\n",
        "    with open(text_file_path, 'w+') as file:\n",
        "        file.write('Vysledky mereni mrtve doby:\\n')\n",
        "        file.write('Typ_Datum_kamera    Hlava_okno  Pocet_akum_impulsu  Acq_time  Count_rate\\n')\n",
        "\n",
        "    dead_time_path = glob(os.path.join(md, 'MD_*.dcm'))[0]\n",
        "    pozadi_path = glob(os.path.join(md, 'Pozadi_*.dcm'))[0]\n",
        "    data_paths = [dead_time_path, pozadi_path]\n",
        "    \n",
        "    dt_data = pydicom.dcmread(dead_time_path)\n",
        "    pozadi_data = pydicom.dcmread(pozadi_path)\n",
        "    datas = [dt_data, pozadi_data]\n",
        "\n",
        "    for dicom_data, path in zip(datas, data_paths):\n",
        "        # Get the base filename without extension\n",
        "        base_filename = os.path.basename(path)\n",
        "        filename_without_extension = os.path.splitext(base_filename)[0]\n",
        "\n",
        "        # Access the custom group containing Dataset Names and print them\n",
        "        if (0x0011, 0x1012) in dicom_data:\n",
        "            dataset_names = dicom_data[0x0011, 0x1012].value\n",
        "            dataset_acq_time = dicom_data[0x0018, 0x1242].value*0.001\n",
        "\n",
        "            # Extract the pixel array from the DICOM data\n",
        "            if 'PixelData' in dicom_data:\n",
        "                pixel_array = dicom_data.pixel_array\n",
        "\n",
        "                # Check if the pixel array has the expected number of slices\n",
        "                num_slices = pixel_array.shape[0]\n",
        "                if num_slices != len(dataset_names):\n",
        "                    print(\"Warning: Number of slices does not match the number of dataset names.\")\n",
        "\n",
        "                # Create a figure and a 2x3 grid of subplots\n",
        "                fig, axes = plt.subplots(2, 3, figsize=(15, 10), dpi = 200)\n",
        "                \n",
        "                # Flatten the axes array for easy iteration\n",
        "                axes = axes.flatten()\n",
        "\n",
        "                # Separate the indices of \"Head1\" and \"Head2\" datasets\n",
        "                head1_indices = [i for i, name in enumerate(dataset_names) if \"Head1\" in name]\n",
        "                head2_indices = [i for i, name in enumerate(dataset_names) if \"Head2\" in name]\n",
        "\n",
        "                # Loop through each \"Head1\" slice and plot it in the first row\n",
        "                for idx, head1_idx in enumerate(head1_indices):\n",
        "                    ax = axes[idx]\n",
        "                    ax.imshow(pixel_array[head1_idx], cmap='gray')\n",
        "                    ax.set_title(dataset_names[head1_idx])\n",
        "                    ax.axis('off')  # Hide the axes ticks\n",
        "\n",
        "                    # Calculate and print the sum of pixel values\n",
        "                    pixel_sum = pixel_array[head1_idx].sum()\n",
        "                    count_rate = pixel_sum / dataset_acq_time\n",
        "                    with open(text_file_path, 'a+') as file:\n",
        "                        file.write(f\"{filename_without_extension}   {dataset_names[head1_idx]}  {pixel_sum} {dataset_acq_time} {round(count_rate,2)}\\n\")\n",
        "\n",
        "                # Loop through each \"Head2\" slice and plot it in the second row\n",
        "                for idx, head2_idx in enumerate(head2_indices):\n",
        "                    ax = axes[idx + 3]\n",
        "                    ax.imshow(pixel_array[head2_idx], cmap='gray')\n",
        "                    ax.set_title(dataset_names[head2_idx])\n",
        "                    ax.axis('off')  # Hide the axes ticks\n",
        "\n",
        "                    # Calculate and print the sum of pixel values\n",
        "                    pixel_sum = pixel_array[head2_idx].sum()\n",
        "                    count_rate = pixel_sum / dataset_acq_time\n",
        "                    with open(text_file_path, 'a+') as file:\n",
        "                        file.write(f\"{filename_without_extension}   {dataset_names[head2_idx]} {pixel_sum} {dataset_acq_time} {round(count_rate,2)}\\n\")\n",
        "                        file.close()\n",
        "\n",
        "                # Adjust layout to avoid overlap\n",
        "                fig.savefig(os.path.join(md, f'{filename_without_extension}.jpg'), bbox_inches='tight')\n",
        "                plt.close()\n",
        "            else:\n",
        "                print(\"No image data found in the DICOM file.\")\n",
        "        else:\n",
        "            print(\"The DICOM file does not contain the expected custom group with dataset names.\")\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ZKOUŠKA JESTLI VŠE FUNGUJE A FUNGUJE\n",
        "\n",
        "from dicom_file_separator import separate_dicom_file\n",
        "from tew_correction import tew_correction\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "path = \"Discovery/MD_08072024_povedene/MD_08072024_Discovery.dcm\"\n",
        "images = separate_dicom_file(path)\n",
        "tew_1 = tew_correction(images[\"Head1_EM\"], images[\"Head1_SC1\"], images[\"Head1_SC2\"])\n",
        "\n",
        "bez_korekce = np.sum(images[\"Head1_EM\"])/images[\"Acq_time\"]\n",
        "s_korekci = np.sum(tew_1)/images[\"Acq_time\"]\n",
        "\n",
        "print(bez_korekce, s_korekci)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'dicom_file_separator'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# DISCOVERY DATA mrtve doby\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdicom_file_separator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m separate_dicom_file\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtew_correction\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tew_correction\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'dicom_file_separator'"
          ]
        }
      ],
      "source": [
        "# DISCOVERY DATA mrtve doby\n",
        "\n",
        "from dicom_file_separator import separate_dicom_file\n",
        "from tew_correction import tew_correction\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "discovery_folder = 'Discovery'\n",
        "discovery_mds = sorted(glob(os.path.join(discovery_folder, 'MD*')))\n",
        "\n",
        "# je nutne si preddefinovat obrazek predem\n",
        "dt_fig = Graf_1_2(12, None,\n",
        "               \"Count rates spočtené pouze z fotopíku\", \"Aktivita [MBq]\", \"Count rate [kcps]\",\n",
        "               \"Count rates spočtené po TEW korekci\", \"Aktivita [MBq]\", \"Count rate [kcps]\",\n",
        "               (20, 8))\n",
        "\n",
        "# arraye pro doplňování Countrates\n",
        "cr_1_no_corr_array = []\n",
        "cr_2_no_corr_array = []\n",
        "cr_1_tew_corr_array = []\n",
        "cr_2_tew_corr_array = []\n",
        "\n",
        "for md in discovery_mds:\n",
        "    ### nejprve rozhazeni jednotlivych dat\n",
        "    dead_time_path = glob(os.path.join(md, 'MD_*.dcm'))[0]\n",
        "    pozadi_path = glob(os.path.join(md, 'Pozadi_*.dcm'))[0]\n",
        "\n",
        "    dt_data = separate_dicom_file(dead_time_path)\n",
        "    bg_data = separate_dicom_file(pozadi_path)\n",
        "\n",
        "    dt_acq_time = dt_data[\"Acq_time\"]\n",
        "    bg_acq_time = bg_data[\"Acq_time\"]\n",
        "    datum = dt_data[\"Acq_date\"]\n",
        "    aktivita = aktivity[datum]\n",
        "\n",
        "    dt_1_no_corr = dt_data[\"Head1_EM\"]\n",
        "    bg_1_no_corr = bg_data[\"Head1_EM\"]\n",
        "\n",
        "    dt_1_tew_corr = tew_correction(dt_data[\"Head1_EM\"], dt_data[\"Head1_SC1\"], dt_data[\"Head1_SC2\"])\n",
        "    bg_1_tew_corr = tew_correction(bg_data[\"Head1_EM\"], bg_data[\"Head1_SC1\"], bg_data[\"Head1_SC2\"])\n",
        "\n",
        "    dt_2_no_corr = dt_data[\"Head2_EM\"]\n",
        "    bg_2_no_corr = bg_data[\"Head2_EM\"]\n",
        "    \n",
        "    dt_2_tew_corr = tew_correction(dt_data[\"Head2_EM\"], dt_data[\"Head2_SC1\"], dt_data[\"Head2_SC2\"])\n",
        "    bg_2_tew_corr = tew_correction(bg_data[\"Head2_EM\"], bg_data[\"Head2_SC1\"], bg_data[\"Head2_SC2\"])\n",
        "\n",
        "    ### ----\n",
        "    ### vypocty count rates\n",
        "\n",
        "    cr_1_no_corr = np.sum(dt_1_no_corr)/dt_acq_time - np.sum(bg_1_no_corr)/bg_acq_time\n",
        "    cr_1_no_corr_array.append(cr_1_no_corr*0.001)\n",
        "\n",
        "    cr_2_no_corr = np.sum(dt_2_no_corr)/dt_acq_time - np.sum(bg_2_no_corr)/bg_acq_time\n",
        "    cr_2_no_corr_array.append(cr_2_no_corr*0.001)\n",
        "\n",
        "    cr_1_tew_corr = np.sum(dt_1_tew_corr)/dt_acq_time - np.sum(bg_1_tew_corr)/bg_acq_time\n",
        "    cr_1_tew_corr_array.append(cr_1_tew_corr*0.001)\n",
        "\n",
        "    cr_2_tew_corr = np.sum(dt_2_tew_corr)/dt_acq_time - np.sum(bg_2_tew_corr)/bg_acq_time\n",
        "    cr_2_tew_corr_array.append(cr_2_tew_corr*0.001)\n",
        "\n",
        "### ----\n",
        "### vyploteni do obrazku\n",
        "dt_fig.fig[0].plot(aktivity.values(), cr_1_no_corr_array, \"o\", color = \"red\", label = \"Hlava 1 (ANT)\")\n",
        "dt_fig.fig[0].plot(aktivity.values(), cr_2_no_corr_array, \"o\", color = \"blue\", label = \"Hlava 2 (POS)\")\n",
        "dt_fig.fig[0].legend(loc = 'best', edgecolor = 'black', fontsize = 11)\n",
        "dt_fig.fig[0].set_xlim(0,None)\n",
        "dt_fig.fig[0].set_ylim(0,None)\n",
        "\n",
        "dt_fig.fig[1].plot(aktivity.values(), cr_1_tew_corr_array, \"o\", color = \"red\", label = \"Hlava 1 (ANT)\")\n",
        "dt_fig.fig[1].plot(aktivity.values(), cr_2_tew_corr_array, \"o\", color = \"blue\", label = \"Hlava 2 (POS)\")\n",
        "dt_fig.fig[1].legend(loc = 'best', edgecolor = 'black', fontsize = 11)\n",
        "dt_fig.fig[1].set_xlim(0,None)\n",
        "dt_fig.fig[1].set_ylim(0,None)\n",
        "\n",
        "dt_fig.Figure.savefig(os.path.join(discovery_folder, 'grafy_mrtve_doby.jpg'), bbox_inches = \"tight\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPS9LmK4fyIorOF99S2Fobj",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
